<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Converting CRAFT to TFLite: A Guide to PyTorch-TFLite Conversion | Tulasi Ram</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Converting CRAFT to TFLite: A Guide to PyTorch-TFLite Conversion" />
<meta name="author" content="Tulasi Ram" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Learn how to convert PyTorch pretrained model to TFLite Format" />
<meta property="og:description" content="Learn how to convert PyTorch pretrained model to TFLite Format" />
<link rel="canonical" href="https://tulasi.dev/craft-in-tflite" />
<meta property="og:url" content="https://tulasi.dev/craft-in-tflite" />
<meta property="og:site_name" content="Tulasi Ram" />
<meta property="og:image" content="https://tulasi.dev/images/flow_resized.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-24T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://tulasi.dev/craft-in-tflite","@type":"BlogPosting","headline":"Converting CRAFT to TFLite: A Guide to PyTorch-TFLite Conversion","dateModified":"2020-11-24T00:00:00-06:00","datePublished":"2020-11-24T00:00:00-06:00","image":"https://tulasi.dev/images/flow_resized.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://tulasi.dev/craft-in-tflite"},"author":{"@type":"Person","name":"Tulasi Ram"},"description":"Learn how to convert PyTorch pretrained model to TFLite Format","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://tulasi.dev/feed.xml" title="Tulasi Ram" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','G-V8KNGXYMX8','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Tulasi Ram</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Converting CRAFT to TFLite: A Guide to PyTorch-TFLite Conversion</h1><p class="page-description">Learn how to convert PyTorch pretrained model to TFLite Format</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-11-24T00:00:00-06:00" itemprop="datePublished">
        Nov 24, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Tulasi Ram</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      8 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#tflite">tflite</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#optimization">optimization</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#onnx">onnx</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#craft">craft</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#text-detector">text-detector</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/tulasiram58827/portfolio/tree/master/_notebooks/2020-11-24-craft-tflite-conversion.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/tulasiram58827/portfolio/master?filepath=_notebooks%2F2020-11-24-craft-tflite-conversion.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/tulasiram58827/portfolio/blob/master/_notebooks/2020-11-24-craft-tflite-conversion.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Brief-Overview-of-the-CRAFT-Model">Brief Overview of the CRAFT Model </a></li>
<li class="toc-entry toc-h2"><a href="#TFLite-Conversion-Flow">TFLite Conversion Flow </a>
<ul>
<li class="toc-entry toc-h3"><a href="#PyTorch-Model-to-ONNX-Model">PyTorch Model to ONNX Model </a></li>
<li class="toc-entry toc-h3"><a href="#Compare-ONNX-output-with-Pytorch-Model-Output:">Compare ONNX output with Pytorch Model Output: </a></li>
<li class="toc-entry toc-h3"><a href="#ONNX-Model-to-TensorFlow-SavedModel">ONNX Model to TensorFlow SavedModel </a></li>
<li class="toc-entry toc-h3"><a href="#TensorFlow-SavedModel-to-TFLite">TensorFlow SavedModel to TFLite </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Dynamic-Range-Quantization">Dynamic Range Quantization </a></li>
<li class="toc-entry toc-h4"><a href="#Float16-Quantization">Float16 Quantization </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Running-inference-with-TFLite-Models">Running inference with TFLite Models </a></li>
<li class="toc-entry toc-h2"><a href="#Results">Results </a></li>
<li class="toc-entry toc-h2"><a href="#Conclusion">Conclusion </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-11-24-craft-tflite-conversion.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is an end-to-end tutorial on how to convert a PyTorch model to TensorFlow Lite (TFLite) using ONNX. Specifically, we will be using the CRAFT model (proposed in <a href="https://arxiv.org/pdf/1904.01941">this paper</a>) which is essentially a text detector. Above is the overview of what’s covered in the tutorial -</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Please open the notebooks included in this <a href="https://github.com/tulasiram58827/craft_tflite">repository</a> and follow along with this blog post.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>You may also directly download already converted TFLite Models from this <a href="https://github.com/tulasiram58827/craft_tflite">Repository</a>. Also pre-converted now available in <a href="https://tfhub.dev/tulasiram58827/lite-model/craft-text-detector/dr/1">Tensorflow Hub</a>.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Brief-Overview-of-the-CRAFT-Model">
<a class="anchor" href="#Brief-Overview-of-the-CRAFT-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Brief Overview of the CRAFT Model<a class="anchor-link" href="#Brief-Overview-of-the-CRAFT-Model"> </a>
</h2>
<p>Character Region Awareness for Text Detection in short <strong>CRAFT</strong> was proposed in <a href="https://arxiv.org/pdf/1904.01941">this paper</a> and is known for its efficiency as well as precise performance
The main principle of <strong>CRAFT</strong> is to localize the individual character regions and link the detected characters to text instances.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>CRAFT</strong> produces two scores for each <em>character-character region score</em> and <em>affinity score</em>.</p>
<ul>
<li><strong>Character Region Score is used to localize the individual character</strong></li>
<li><strong>Affinity Score is used to group each character into a single instance.</strong></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://lh5.googleusercontent.com/t3J001eXsOz1ZHcRw-csq2veMrsRK_SNJ8xOVmFFOomffcIBbqEZ00oVrGNcbId6Hg2PQRox1SCGCW5IA8T8L9IY6fTcx2ZqGyOt2xe4XSOItzgV5nIT-eNR1MCwUM9Wx4p8m26q" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we all know in most of the image detectors use <strong>VGG16</strong> as feature extractor <strong>CRAFT</strong> is not an exception for it and for decoding the architecture is similar to UNet.</p>
<p><img src="https://lh5.googleusercontent.com/eq-ksP-g33SDXlOCNXpgGPwF2iW-03-VAmM-v9iM13mCkBPt15uXSTqLbv_TsXPFFfHVg3jcNgPPxnmcK9G_TQPGFWMWTkBRryMZUaEyRYPe0PJ0rCEgUNBgrdsPFdEcMe7n3_dm" alt=""></p>
<p>The above diagram is taken from the original <a href="https://arxiv.org/pdf/1904.01941.pdf">paper</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="TFLite-Conversion-Flow">
<a class="anchor" href="#TFLite-Conversion-Flow" aria-hidden="true"><span class="octicon octicon-link"></span></a>TFLite Conversion Flow<a class="anchor-link" href="#TFLite-Conversion-Flow"> </a>
</h2>
<p><img src="https://paper-attachments.dropbox.com/s_26EA9AD010A0BB211BCF8D0337C8A342D7ED67947FA9F0B435D128AAF3F2C824_1606055863622_flow.png" alt="">
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Currently, the integer quantization is erroring out and it has been reported to the TensorFlow Lite team.
</div>
<em>Update from TFLite team: Currently support for NCHW image format(like those converted from PyTorch) is quite limited at this moment, which caused this issue with full integer quantized model.</em>
<p>You can find the full reply from TensorFlow Lite team <a href="https://github.com/tulasiram58827/craft_tflite/issues/1#issuecomment-734015155">here</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://github.com/clovaai/CRAFT-pytorch">Clove AI</a> team already provided pre-trained weights we can use for making inference on images. But the framework(PyTorch) is not ideal for mobile applications and also for low latency devices like Raspberry Pi and Fully Integer Devices like Google Coral and MicroControllers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>TensorFlow Lite is a framework that is well suited for running Deep Learning Models on edge devices and mobile devices. Now a days usage of edge devices become popular mainly due to 3 reasons</p>
<ul>
<li>Lower Latency</li>
<li>No requirement of Internet</li>
<li>Privacy Protection</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is why we first convert these pre-trained weights to TFLite which would be more suitable for low latency devices and mobile applications.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="PyTorch-Model-to-ONNX-Model">
<a class="anchor" href="#PyTorch-Model-to-ONNX-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>PyTorch Model to ONNX Model<a class="anchor-link" href="#PyTorch-Model-to-ONNX-Model"> </a>
</h3>
<p>Refer this <a href="https://github.com/tulasiram58827/craft_tflite/blob/main/colabs/pytorch_to_onnx.ipynb">notebook</a> for complete code details mentioned in this section.</p>
<p><a href="https://github.com/onnx/onnx">Open Neural Network Exchange</a> in short <strong>ONNX</strong> is an open format built to represent machine learning models.
The best thing about ONNX is interoperability. You can develop in your preferred framework without worrying about downstream inference applications.
Exporting the models to ONNX format requires some mandatory parameters:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>Pre-trained Model</li>
<li>Sample Input</li>
<li>Path to save the model</li>
<li>Input and Output Node names</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">pytorch_model</span><span class="p">,</span> 
                  <span class="n">x</span><span class="p">,</span> 
                  <span class="s1">'craft.onnx'</span><span class="p">,</span> 
                  <span class="n">opset_version</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  
                  <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                  <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s1">'input'</span><span class="p">],</span> 
                  <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s1">'output'</span><span class="p">],</span> 
                  <span class="n">dynamic_axes</span><span class="o">=</span> <span class="n">shape_dict</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are some details about the above code snippet -</p>
<ul>
<li>
<p><code>export()</code> function executes the model and records a trace of operators that are used to compute output.</p>
</li>
<li>
<p>To execute the model we need to provide the <em>input</em>. This value can be random as long as type and dimensions are matched because the export function just runs the model to trace the operators that are being used to compute output.</p>
</li>
<li>
<p>Exported ONNX model will be of fixed dimension unless specified in the <code>dynamic_axes</code> parameter. In the above code we specified batch_size, width and height of the image are dynamic and the channels which are not specified in the <code>dynamic_axes</code> will be fixed according to input dimension.</p>
</li>
<li>
<p>To visualize the exported onnx model you can use this <a href="https://netron.app/">tool</a>.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once the model is exported, load the model and verify the model structure and confirm whether the model has a valid schema or not.</p>
<p>The below code snippet checks whether the exported onnx model has a valid schema.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'craft.onnx'</span><span class="p">)</span>
<span class="n">onnx</span><span class="o">.</span><span class="n">checker</span><span class="o">.</span><span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Expected Output:</p>
<p>Raises Runtime Error if model is not valid. If valid no output.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compare-ONNX-output-with-Pytorch-Model-Output:">
<a class="anchor" href="#Compare-ONNX-output-with-Pytorch-Model-Output:" aria-hidden="true"><span class="octicon octicon-link"></span></a>Compare ONNX output with Pytorch Model Output:<a class="anchor-link" href="#Compare-ONNX-output-with-Pytorch-Model-Output:"> </a>
</h3>
<p>To check whether the exported ONNX model was faulty or not follow these steps:</p>
<ul>
<li>Create a Sample Input</li>
<li>Run pre-trained Pytorch Model and save output</li>
<li>Run exported ONNX model and save output</li>
<li>Compare both pytorch output and ONNX model output.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below is the code snippet required to implement the above steps:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ort_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="s1">'craft.onnx'</span><span class="p">)</span>
<span class="n">ort_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">ort_session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">:</span><span class="n">onnx_runtime_input</span><span class="p">}</span>
<span class="n">ort_outs</span> <span class="o">=</span> <span class="n">ort_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">ort_inputs</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">pytorch_out</span><span class="p">,</span> <span class="n">ort_outs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-03</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The above code snippet compares both pytorch model output and onnx model output and errors out if the outputs are not matched with the tolerance mentioned.</p>
<p>It compares the difference between pytorch output and onnx output to 
 <code>atol+rtol*abs(onnx output)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can refer to this <a href="https://numpy.org/doc/stable/reference/generated/numpy.testing.assert_allclose.html">documentation</a> for more details about this function.
If the ONNX conversion was faulty then the assertion statement would have errored out.</p>
<p>Great! We converted to <strong>ONNX.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ONNX-Model-to-TensorFlow-SavedModel">
<a class="anchor" href="#ONNX-Model-to-TensorFlow-SavedModel" aria-hidden="true"><span class="octicon octicon-link"></span></a>ONNX Model to TensorFlow SavedModel<a class="anchor-link" href="#ONNX-Model-to-TensorFlow-SavedModel"> </a>
</h3>
<p>Refer to this <a href="https://github.com/tulasiram58827/craft_tflite/blob/main/colabs/onnx_to_tflite.ipynb">notebook</a> for complete code details mentioned in this section.</p>
<p>As mentioned earlier, the best feature of ONNX is interoperability. Once we have the access to the ONNX model we can convert it into any other existing popular frameworks very easily.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let’s see how to convert the ONNX model to the TensorFlow SavedModel.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">onnx_tf.backend</span> <span class="kn">import</span> <span class="n">prepare</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'craft.onnx'</span><span class="p">)</span>
<span class="n">tf_rep</span> <span class="o">=</span> <span class="n">prepare</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
<span class="n">tf_rep</span><span class="o">.</span><span class="n">export_graph</span><span class="p">(</span><span class="s1">'craft_tf_graph'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After exporting to TensorFlow graphs we can inspect the graph using the same <a href="https://netron.app/">tool</a>
which we used to visualize the onnx model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-error">
    <svg class="octicon octicon-alert" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path></svg>
    <strong>Warning: </strong>Please refer to the installation <a href="https://github.com/tulasiram58827/craft_tflite/blob/main/README.md#installation">instructions</a> for validity of onnx and  onnx_tf versions.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A SavedModel contains all the information about the TensorFlow program, along with weights and computation. As we don’t require any extra code to build the model it is very easy to share or deploy TensorFlow saved models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The file structure of SavedModel <code>craft_tf_graph</code>  will be as follows:</p>

<pre><code>craft_tf_graph
   |----  saved_model.pb
       |----  assets
       |----  variables
           |---- variables.data-00000-of-00001
           |---- variables.index</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <code>saved_model.pb</code> contains an actual model and set of named signatures each identifying a function that accepts input tensors and produces output tensors.</p>
<p>The <code>variables</code> directory contains standard checkpoints and <code>assets</code> directory contains files used by tensorflow graph. <code>assets</code> directory is unused in this example as saved model has no requirement of extra files.</p>
<p>To know more about TensorFlow SavedModel please refer to this <a href="https://www.tensorflow.org/guide/saved_model">guide</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can load the saved model assuming it is Keras saved model. Below is the code
snippet to load the saved model:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s1">'craft_tf_graph'</span><span class="p">)</span>
<span class="c1"># or model = tf.saved_model.load('craft_tf_graph')</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can easily convert to the TFLite Model easily from the saved model. But inorder to change any input dimension you can set it by loading the concrete function from the saved model.</p>
<p>Below is the code snippet to set the input shape required for the TFLite format.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">concrete_func</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">signatures</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">DEFAULT_SERVING_SIGNATURE_DEF_KEY</span><span class="p">]</span>
<span class="n">concrete_func</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="mi">600</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TensorFlow-SavedModel-to-TFLite">
<a class="anchor" href="#TensorFlow-SavedModel-to-TFLite" aria-hidden="true"><span class="octicon octicon-link"></span></a>TensorFlow SavedModel to TFLite<a class="anchor-link" href="#TensorFlow-SavedModel-to-TFLite"> </a>
</h3>
<p>To convert a TensorFlow model into TensorFlow Lite model can be done from 3 ways:</p>
<ul>
<li>From Saved Model</li>
<li>From Keras Model</li>
<li>From Concrete Function</li>
</ul>
<p>You can refer to this <a href="https://www.tensorflow.org/lite/performance/post_training_quantization">blog</a> for various conversion techniques. We will convert to TFLite from concrete function.</p>
<p>Below is the code snippet to load the concrete function into the TFLiteConverter.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">converter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">TFLiteConverter</span><span class="o">.</span><span class="n">from_concrete_functions</span><span class="p">([</span><span class="n">concrete_func</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While converting to TFLite we can choose several quantization methods. Refer to this <a href="https://www.tensorflow.org/lite/performance/post_training_quantization">guide</a> for various Post training Quantization techniques.</p>
<ul>
<li>Dynamic Range Quantization</li>
<li>Float16 Quantization</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Dynamic-Range-Quantization">
<a class="anchor" href="#Dynamic-Range-Quantization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dynamic Range Quantization<a class="anchor-link" href="#Dynamic-Range-Quantization"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Default Optimization is <strong>Dynamic Range</strong> Quantization.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">converter</span><span class="o">.</span><span class="n">optimizations</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">Optimize</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Float16-Quantization">
<a class="anchor" href="#Float16-Quantization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Float16 Quantization<a class="anchor-link" href="#Float16-Quantization"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For <strong>Float16</strong> all other things remain same we just need to add this line</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">converter</span><span class="o">.</span><span class="n">target_spec</span><span class="o">.</span><span class="n">supported_types</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">float16</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Convert and Store the Model:</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf_lite_model</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">convert</span><span class="p">()</span>
<span class="nb">open</span><span class="p">(</span><span class="s1">'craft.tflite'</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">tf_lite_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<table>
<thead>
<tr>
<th><strong>Quantization Type</strong></th>
<th><strong>Model Size</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Dynamic Range</td>
<td>20MB</td>
</tr>
<tr>
<td>Float16</td>
<td>40MB</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Original PyTorch model size is around <strong>80MB</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Running-inference-with-TFLite-Models">
<a class="anchor" href="#Running-inference-with-TFLite-Models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Running inference with TFLite Models<a class="anchor-link" href="#Running-inference-with-TFLite-Models"> </a>
</h2>
<p>Refer to this <a href="https://github.com/tulasiram58827/craft_tflite/blob/main/colabs/tflite_inference.ipynb">notebook</a> for complete code details mentioned in this section.</p>
<p>Once the TFLite models are generated we need to make sure they are working as expected. So let’s do inference on the real image and check the output.</p>
<p>Run the preprocessing steps mentioned in this <a href="https://github.com/tulasiram58827/craft_tflite/blob/main/colabs/tflite_inference.ipynb">notebook</a> before feeding to the tflite model.</p>
<p>Below is the code snippet to run the inference with TFLite model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">interpreter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s1">'craft.tflite'</span><span class="p">)</span>
<span class="n">interpreter</span><span class="o">.</span><span class="n">allocate_tensors</span><span class="p">()</span>
<span class="n">input_details</span> <span class="o">=</span> <span class="n">interpreter</span><span class="o">.</span><span class="n">get_input_details</span><span class="p">()</span>
<span class="n">output_details</span> <span class="o">=</span> <span class="n">interpreter</span><span class="o">.</span><span class="n">get_output_details</span><span class="p">()</span>        
<span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'shape'</span><span class="p">]</span>
<span class="n">interpreter</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="n">input_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'index'</span><span class="p">],</span> <span class="n">input_data</span><span class="p">)</span>
<span class="n">interpreter</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">interpreter</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">output_details</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'index'</span><span class="p">])</span>    
<span class="n">feature</span> <span class="o">=</span>  <span class="n">interpreter</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">output_details</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">'index'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After the post-processing steps mentioned in this <a href="https://github.com/tulasiram58827/craft_tflite/blob/main/colabs/tflite_inference.ipynb">notebook</a> the output image (with dynamic range quantized model) would look like this alongside with the output of the original model output.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Results">
<a class="anchor" href="#Results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results<a class="anchor-link" href="#Results"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Output with Dynamic Range Quantized Model:</strong></p>
<p><img src="https://paper-attachments.dropbox.com/s_26EA9AD010A0BB211BCF8D0337C8A342D7ED67947FA9F0B435D128AAF3F2C824_1606194525784_CRAFT_TFLITE_CONVERSION.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Output with Float16 Quantized Model:</strong></p>
<p><img src="https://paper-attachments.dropbox.com/s_26EA9AD010A0BB211BCF8D0337C8A342D7ED67947FA9F0B435D128AAF3F2C824_1606194562401_CRAFT_TFLITE_CONVERSION+1.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It is clearly evident that the results of Float16 quantized model are better than results of Dynamic Range quantized model but at the cost of model size.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">
<a class="anchor" href="#Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion<a class="anchor-link" href="#Conclusion"> </a>
</h2>
<p>In this post we have covered all the steps required to convert any PyTorch pre-trained model to TFLite format. If you want to use the same notebook for all of the mentioned steps you can use this <a href="https://github.com/tulasiram58827/craft_tflite/blob/main/colabs/CRAFT_TFLITE.ipynb">notebook</a>.</p>
<p>Wondering about how the CRAFT model would perform in the mobile device? Refer to this <a href="https://sayak.dev/optimizing-text-detectors">blog post</a> that compares the CRAFT model with the <a href="https://arxiv.org/abs/1704.03155">EAST model</a> w.r.t. many useful metrics such as memory, inference latency, performance and so on.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Acknowledgments:</strong></p>
<p><em>Thanks to <a href="https://twitter.com/RisingSayak">Sayak Paul</a> , <a href="https://twitter.com/khanhlvg">Le Viet Gia Khanh</a>(from TFLite team) for their constant guidance.</em></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="tulasiram58827/portfolio"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/craft-in-tflite" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Deep Learning, Speech Recognition, Computer Vision</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/tulasiram58827" title="tulasiram58827"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Tulasi123789" title="Tulasi123789"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
